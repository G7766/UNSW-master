{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Health specific activity 2</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We revisit last week's activity to understand what we left aside, and do part of what we did better.\n",
    "\n",
    "Again, the second set of data available at https://www.gen-agedcaredata.gov.au/Resources/Access-data/2017/August/GEN-Data-People-using-aged-care, namely, *People using aged care services, 30 June 2013â€“2016 (CSV, 67.3 MB)*, is supposed to be downloaded and saved in the directory where this jupyter notebook sheet is run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, let us start from scratch. To read the contents of a csv (for *comma separated values*) file in Python, it is convenient to open the file with the **open** function, which returns a \"handle\" to the file that can then be passed as an argument to the **reader** function of the **csv** module, provided the latter has been imported:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('People_2013to2016_GENdata.csv') as csv_file:\n",
    "    aged_care_data = csv.reader(csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The contents of the file can then be read line by line by calling again and again the **next** function, with *aged_care_data* as argument. The first call to **next** should return the result of parsing the first line of the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('People_2013to2016_GENdata.csv') as csv_file:\n",
    "    aged_care_data = csv.reader(csv_file)\n",
    "    print(next(aged_care_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that does not work. We have an encoding problem. Text, data, can be encoded in so many ways, and the default encoding of **utf-8** turns out not to be appropriate here. Another encoding has been used to encode the contents of this file. Encodings are a tricky matter, and kind of an advanced topic. But here we have a concrete problem and we have to bite the bullet in one way or another! A Google search suggests a method to try and guess the encoding of a file. It uses the **detect** method of the **chardet** module. Let us try and use that by just letting **detect** examine the first line of the file, and then the second line of the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import chardet\n",
    "\n",
    "with open('People_2013to2016_GENdata.csv', 'rb') as csv_file:\n",
    "    print(chardet.detect(next(csv_file)))\n",
    "    print(chardet.detect(next(csv_file)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first line of the file makes **chardet** believe that we are dealing with **ascii** encoding; the second line makes **chardet** believe that we are dealing with **Windows-1252** encoding. If we open the file in an editor and look at the first two lines, here is what we can get (with some editors):\n",
    "\n",
    "YEAR,STATE,ACPR CODE,ACPR NAME,PROGCODE,ADMTYPE,HOME CARE LEVEL,AGE GROUP,SEX,ATSI CODE,LAN,COB\n",
    "\n",
    "2013,NSW,101,Central Coast,106889,,L 2,85\\22689,F,,English ,Australia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first line just contains the names of the fields, and consists of nothing but uppercase letters and commas. The second line is the first record, containing the comma separated values of the fields for some person. That line contains a strange \\226 that we assume stands for a special character, which is not part of the ascii character set. This is probably what gives **chardet** a clue (and makes it believe with 73% confidence) that that line, and therefore the whole file, could be encoded using **Windows-1252**. Rich of that insight, let us modify our original code so that the **open** function does not implicitly use the default **utf-8** encoding, but explicitly uses the **Windows-1252** encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('People_2013to2016_GENdata.csv', encoding = 'Windows-1252') as csv_file:\n",
    "    aged_care_data = csv.reader(csv_file)\n",
    "    print(next(aged_care_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good, that works, we've got the list of names of all fields! Let us rather read the first two lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('People_2013to2016_GENdata.csv', encoding = 'Windows-1252') as csv_file:\n",
    "    aged_care_data = csv.reader(csv_file)\n",
    "    print(next(aged_care_data))\n",
    "    print(next(aged_care_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still all good. And we discover that \\226 was used to encode the large hyphen to separate the lower and upper bounds of the age group (from 85 to 89)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we did not use **csv.reader**, we could, as we did when exploring encodings with **chardet**, read the contents of the file line by line passing *csv_file* as argument to **next**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('People_2013to2016_GENdata.csv', encoding = 'Windows-1252') as csv_file:\n",
    "    print(next(csv_file))\n",
    "    print(next(csv_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then what we get is a string, one string per line. Using the **reader** function of the **csv** module and calling **next** on *aged_care_data* rather than on *csv_file*, we get instead, for each line, a list of strings, with as many strings in the list as comma-separated values on the line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last week, we created a list to keep track of all records for the year 2016, ignoring all other years. Let us do it a in better way, reading the contents of the file line by line, discarding the records that are not for 2016, and keeping all others. This is more efficient than first creating a list of all records, and then, from that list, creating a new list of records for 2016 only. The way our list is created is a Pythonic construct known as list comprehension: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('People_2013to2016_GENdata.csv', encoding = 'Windows-1252') as csv_file:\n",
    "    aged_care_data = csv.reader(csv_file)\n",
    "    records_for_2016 = [other_fields for year, *other_fields in aged_care_data if year == '2016']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We surely remember from last week how many records we got, don't we?... Let us check we get the same number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(len(records_for_2016))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we revisit further what we did last week, let us see what are the possible values for the last field, COB (country of birth). We use a set which, in contrast to a list, has no duplicate element, so it is a good way to \"collapse\" a collection of (possibly duplicated) values to the collection of distinct values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(set(record[-1] for record in records_for_2016))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no natural order for the elements in a set. Here we have a set with 4 elements and **print** displays them in an arbitrary order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see what are the possible values for the second to last field, LAN (*language*):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(set(record[-2] for record in records_for_2016))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now back again to what we did last week, when we organised the data for 2016, grouping them by state (the first field) thanks to a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "records_per_state = defaultdict(list)\n",
    "for state, *other_fields in records_for_2016:\n",
    "    records_per_state[state].append(other_fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check this works too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for state in sorted(records_per_state):\n",
    "    print(f'{state}\\t{len(records_per_state[state])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than using a standard dictionary, this time we use a **defaultdict**, imported from the **collections** module. A few examples will do better than long explanations to illustrate the benefits of a **defaultdict** over a standard dictionary. Essentially, when a new key is processed in the context of **defaultdict** with lists as values, a default value, namely, an empty list, is created, to which the first record can be appended:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Does not work\n",
    "D = {}\n",
    "D['ACT'].append('A record for ACT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Does work\n",
    "D = defaultdict(list)\n",
    "D['ACT'].append('A record for ACT')\n",
    "print(D)\n",
    "D['ACT'].append('Another record for ACT')\n",
    "print(D)\n",
    "D['ACT'].append('Still another record for ACT')\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we organised the data for 2016 further, grouping them by state (the first field), and for each state, grouping them by gender (the fourth to last field). We examined the data to find out that the possible values for gender are 'M', 'F' and 'U', and made use of that \"knowledge\" to create our dictionaries. Let us do things better:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gender_distribution_per_state = defaultdict(lambda: defaultdict(int))\n",
    "for state in records_per_state:\n",
    "    for *_, gender, _, _, _ in records_per_state[state]:\n",
    "        gender_distribution_per_state[state][gender] += 1\n",
    "    for gender in gender_distribution_per_state[state]:\n",
    "        gender_distribution_per_state[state][gender] /= len(records_per_state[state])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check it still works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for state in sorted(gender_distribution_per_state):\n",
    "    print('State:', state)\n",
    "    for gender in sorted(gender_distribution_per_state[state]):\n",
    "        print(f'\\t{gender}: {gender_distribution_per_state[state][gender] * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the output is actually better, as the category 'U' is output only when there is at least one record (for a given state) that falls in that category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We improved the code by making use of a **defaultdict** again, together with a lambda expression.\n",
    "\n",
    "* **defaultdict(list)**: when encountering a new key, automatically create an empty list as value for that key, so we can always append something to the value of the dictionary for any key, new or not.\n",
    "* **defaultdict(int)**: when encountering a new key, automatically create 0 as value for that key, so we can always add 1 to the value of the dictionary for any key, new or not.\n",
    "* **defaultdict(lambda: defaultdict(int))**: when encountering a new key, automatically create defaultdict(int) as value for that key, so we can use such a dictionary or any key, new or not: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see some practice code to understand lambda expressions, which are nothing by anonymous (unnamed) functions. Here are three lambda expressions for three functions which take no, one or two arguments, respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = lambda: 0\n",
    "print(f())\n",
    "g = lambda x: x + 1\n",
    "print(g(2))\n",
    "h = lambda x, y: x + y\n",
    "print(h(4, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An empty list is created by calling **list**, 0 is created by calling **int**, and a **defaultdict** with 0 as default value is created by calling **lambda: defaultdict(int)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(list(), int(), (lambda: defaultdict(int))())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we organised the data for 2016 even further, grouping them by state (the first field), and for each state, grouping them by age group (the second field), and for each age group, grouping them by gender (the fourth to last field). Again, let us do things better:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gender_distribution_per_state_and_age_group = defaultdict(lambda: defaultdict(lambda: defaultdict(int)))\n",
    "for state in records_per_state:\n",
    "    for *_, age_group, gender, _, _, _ in records_per_state[state]:\n",
    "        gender_distribution_per_state_and_age_group[state][age_group][gender] += 1\n",
    "    for age_group in gender_distribution_per_state_and_age_group[state]:\n",
    "        tally = sum(gender_distribution_per_state_and_age_group[state][age_group].values())\n",
    "        for gender in gender_distribution_per_state_and_age_group[state][age_group]:\n",
    "            gender_distribution_per_state_and_age_group[state][age_group][gender] /= tally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check out what we get for New South Wales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for age_group in sorted(gender_distribution_per_state_and_age_group['NSW']):\n",
    "    print(f'\\t{age_group}:')\n",
    "    for gender in sorted(gender_distribution_per_state_and_age_group['NSW'][age_group]):\n",
    "        print(f'\\t\\t{gender}: {gender_distribution_per_state_and_age_group[\"NSW\"][age_group][gender] * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is the same results as last week, but not as well presented, as we had the percentages for 100+ displayed last. The issue is that the string '0â€“49' lexicographically comes before the string '100+', which comes before the string '50â€“54'. What we need is to order the strings that represent the age groups using for comparison key the leading number:\n",
    "* 0 for '0â€“49',\n",
    "* 100 for '100+',\n",
    "* 50 for '50â€“54'\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what we did last week when we passed an extra argument to **sorted**, to tell the sorting function: do not use the default ordering on strings (the lexicographic ordering), but instead, map the key '0â€“49' to 49, map the key '100+' to 100, map the key '50â€“54' to 50, and order the results based on the values computed from the keys, not from the keys themselves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def age_group_lower_bound(age_group):\n",
    "    lower_bound = 0\n",
    "    for c in age_group:\n",
    "        if not c.isdigit():\n",
    "            break\n",
    "        lower_bound = lower_bound * 10 + int(c)\n",
    "    return lower_bound\n",
    "\n",
    "for age_group in sorted(gender_distribution_per_state_and_age_group['NSW'], key = age_group_lower_bound):\n",
    "    print(f'\\t{age_group}:')\n",
    "    for gender in sorted(gender_distribution_per_state_and_age_group['NSW'][age_group]):\n",
    "        print(f'\\t\\t{gender}: {gender_distribution_per_state_and_age_group[\"NSW\"][age_group][gender] * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is some practice code to understand how *age_group_lower_bound* does what we want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = '5230â€“5340'\n",
    "for c in x:\n",
    "    print(c, end = ' ')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = '5230â€“5340'\n",
    "for c in x:\n",
    "    if not c.isdigit():\n",
    "        break\n",
    "    print(c, end = ' ')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = '5230â€“5340'\n",
    "n = 0\n",
    "for c in x:\n",
    "    if not c.isdigit():\n",
    "        break\n",
    "    # c is a one character string, one of '0', '1',... '9', that we convert to 0, 1,... 9, respectively\n",
    "    n = n * 10 + int(c)\n",
    "    print(n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
