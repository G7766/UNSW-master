{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP9318-Lab3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "1. This note book contains instructions for **COMP9318-Lab3**.\n",
    "\n",
    "* You are required to complete your implementation in a file `submission.py` provided along with this notebook.\n",
    "\n",
    "* You are not allowed to print out unnecessary stuff. We will not consider any output printed out on the screen. All results should be returned in appropriate data structures via corresponding functions.\n",
    "\n",
    "* You can submit your implementation for **Lab3** via following link: http://kg.cse.unsw.edu.au/submit/ .\n",
    "\n",
    "* For each question, we have provided you with detailed instructions along with question headings. In case of any problem, you can post your query @ Piazza.\n",
    "\n",
    "\n",
    "* You are allowed to add other functions and/or import modules (you may have to in this lab), but you are not allowed to define global variables. **Only functions are allowed** in `submission.py`. \n",
    "\n",
    "* You should not import unnecessary modules/libraries, failing to import such modules at test time will lead to errors.\n",
    "\n",
    "* We will provide immediate feedback on your submission. You can access your scores using the online submission portal on the same day. \n",
    "\n",
    "* For **Final Evaluation** we will be using a different dataset, so your final scores may vary.  \n",
    "\n",
    "* You are allowed to submit as many times as you want before the deadline, but **ONLY the latest version will be kept and marked**.\n",
    "\n",
    "* Submission deadline for this assignment is **23:59:59 on 2nd April, 2019**. We will **NOT** accept any late submissions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question-1: Logistic Regression using Gradient Descent\n",
    "\n",
    "* In this lab you are required to implement Logistic Regression using Gradient Descent.\n",
    "* The training data is 2-dimensional data points from two classes namely: class-0, and class-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Col1</th>\n",
       "      <th>Col2</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.464726</td>\n",
       "      <td>-0.552165</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.465277</td>\n",
       "      <td>0.155947</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.367907</td>\n",
       "      <td>0.337509</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.703355</td>\n",
       "      <td>-0.511965</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.193367</td>\n",
       "      <td>0.642282</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Col1      Col2  Label\n",
       "0  0.464726 -0.552165    0.0\n",
       "1 -0.465277  0.155947    0.0\n",
       "2 -0.367907  0.337509    0.0\n",
       "3 -1.703355 -0.511965    0.0\n",
       "4 -0.193367  0.642282    0.0"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data_file='./asset/a'\n",
    "raw_data = pd.read_csv(data_file, sep=',')\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to **implement** logistic regression classifier (i.e., `logistic_regression()` in the file: `submission.py`). The input arguments of `logistic_regression()` are:\n",
    "* `data`: Data in 2-columns format\n",
    "* `labels`: Class-labels\n",
    "* `weights`: The cofficients to be computed, initialized with ZEROS\n",
    "* `num_epochs`: Number of epochs\n",
    "* `learning_rate`: Learning rate of the algorithm \n",
    "\n",
    "The return value of `logistic_regression()` should be a numpy array containing the logistic regression **coefficients**. The bias term should be appended at the start of the array.\n",
    "\n",
    "For example, a sample output is shown in the cell given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-35fa14bbae46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50e-5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mcoefficients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubmission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogistic_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoefficients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/sem/sem3/9318/Lab/Lab3/Lab3_specs/submission.py\u001b[0m in \u001b[0;36mlogistic_regression\u001b[0;34m(data, labels, weights, num_epochs, learning_rate)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlogistic_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m# do not change the heading of the function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#pass # **replace** this line with your code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# m is total number of sample, n is number of column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "import submission as submission\n",
    "\n",
    "## Read in the Data...\n",
    "raw_data = pd.read_csv(data_file, sep=',')\n",
    "labels=raw_data['Label'].values\n",
    "data=np.stack((raw_data['Col1'].values,raw_data['Col2'].values), axis=-1)\n",
    "\n",
    "## Fixed Parameters. Please do not change values of these parameters...\n",
    "weights = np.zeros(3) # We compute the weight for the intercept as well...\n",
    "num_epochs = 50000\n",
    "learning_rate = 50e-5\n",
    "\n",
    "coefficients=submission.logistic_regression(data, labels, weights, num_epochs, learning_rate)\n",
    "print(coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z: [-10.20342907  -2.29067514   5.31366198]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data_file='./asset/a'\n",
    "raw_data = pd.read_csv(data_file, sep=',')\n",
    "raw_data.head()\n",
    "\n",
    "labels=raw_data['Label'].values\n",
    "data=np.stack((raw_data['Col1'].values,raw_data['Col2'].values), axis=-1)\n",
    "\n",
    "\n",
    "## Fixed Parameters. Please do not change values of these parameters...\n",
    "weights = np.zeros(3) # We compute the weight for the intercept as well...\n",
    "num_epochs = 50000\n",
    "learning_rate = 50e-5\n",
    "\n",
    "        \n",
    "def logistic_regression(data, labels, weights, num_epochs, learning_rate):\n",
    "    m,n = np.shape(data) # m is total number of sample, n is number of column\n",
    "    #theta = np.ones(n+1)\n",
    "    n = n + 1\n",
    "    theta = np.array(weights).reshape(n,1)\n",
    "    #print(weights)\n",
    "    #print('theta:',theta)\n",
    "    \n",
    "    max_iterations = num_epochs # num_epochs is max iterations\n",
    "    alpha = learning_rate\n",
    "    \n",
    "    x0 = np.ones((m,1))\n",
    "    x = np.hstack((x0,data))\n",
    "    #print(x)\n",
    "\n",
    "    #y = labels\n",
    "    y = np.array(labels).reshape(m,1)\n",
    "\n",
    "\n",
    "    # GradientDescent:\n",
    "    for i in range(0,max_iterations):\n",
    "        h = np.dot(x, theta)\n",
    "        #print('h:',h)\n",
    "        h = 1/(1+np.exp(-h))         #sigmoid\n",
    "        diff = h - y                #compute the difference, loss function\n",
    "        gardient =  np.dot(np.transpose(x),diff)    #(hj-yj)xj\n",
    "        theta = theta - alpha * gardient           # theta is changinf\n",
    "    theta= np.transpose(theta)\n",
    "    theta = theta[0]\n",
    "    #print(type(theta))\n",
    "    return theta\n",
    "\n",
    "\n",
    "z = logistic_regression(data, labels, weights, num_epochs, learning_rate)\n",
    "print('z:',z)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Environment\n",
    "\n",
    "For testing, we have pre-installed the requisite modules and/or libraries in the testing environment. You are only allowed to use following libraries:\n",
    "* python: 3.6.5\n",
    "* pandas: 0.22.0\n",
    "* numpy: 1.14.3\n",
    "\n",
    "NOTE: <br> \n",
    "* You are required to implement the logistic regression by yourself. You are not allowed to import **SKLEARN** and/or any **OTHER LIBRARY** in Lab3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
